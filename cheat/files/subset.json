[{"id":"0Hadoop hdfs#","section":"Hadoop hdfs#","description":"hadoop streaming","command":"hadoop jar $HADOOP_HOME/hadoop-streaming.jar \\\n    -input myInputDirs \\\n    -output myOutputDir \\\n    -mapper myPythonScript.py \\\n    -reducer /bin/wc \\\n    -file myPythonScript.py"},{"id":"1Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs print sequence file","command":"hdfs dfs -text /path/to/file/hdfs"},{"id":"2Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs Copy Files from one cluster to other","command":"hadoop distcp -pb -overwrite hftp://hdfssource:50070/file/to/copy hdfs://hdfsdest:8020/user/test"},{"id":"3Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs change replication factor of a file","command":"hdfs dfs -setrep -w 2 /my/file"},{"id":"4Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs set replication factor recursive","command":"hdfs dfs -setrep -R -w 1 /my/folder"},{"id":"5Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs chmod change file permissions","command":"hdfs dfs -chmod 1755 /my_file"},{"id":"6Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs chgrp change group of file","command":"hdfs dfs -chgrp group_name /my_file"},{"id":"7Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs print a file","command":"hdfs dfs -cat /my_file"},{"id":"8Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs append to a file","command":"hdfs dfs -appendToFile /local_file.txt /hdfs/my_file.txt"},{"id":"9Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs stream append to a file using pipe / stdin","command":"cat somefile | hdfs dfs -appendToFile - /hdfs/my_file.txt"},{"id":"10Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs copy from local machine to cluster","command":"hdfs dfs -copyFromLocal /local/file.csv /hdfs/folder/"},{"id":"11Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs copy from remote cluster to local machine","command":"hdfs dfs -copyToLocal /hdfs/folder/file.csv /local/folder"},{"id":"12Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs copy from local machine to cluster with overwrite","command":"hdfs dfs -copyFromLocal -f /local/file.csv /hdfs/folder/"},{"id":"13Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs count number of directories, files and bytes","command":"hdfs dfs -count /hdfs/folder/file"},{"id":"14Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs copy file in the cluster","command":"hdfs dfs -cp /source_file /dest_file"},{"id":"15Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs display size of files and directories","command":"hdfs hdfs -du /user/hadoop/dir1"},{"id":"16Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs get access control list ACL of files and directories","command":"hdfs dfs -getfacl /file"},{"id":"17Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs list all files in a directory","command":"hdfs dfs -ls /user/dir1"},{"id":"18Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs delete file","command":"hdfs dfs -rm /file/to/delete"},{"id":"19Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs delete folder","command":"hdfs dfs -rmr /folder/to/delete"},{"id":"20Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs return stat information of the path (basic file info)","command":"hdfs dfs -stat /my_file"},{"id":"21Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs tail a file","command":"hdfs dfs -tail /my_file"},{"id":"22Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs create / touch a file","command":"hdfs hdfs -touchz /path/to/myfile.txt"},{"id":"23Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs put / copy file to local to cluster","command":"hdfs dfs -put localfile /user/hadoop/hadoopfile"},{"id":"24Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs stream result of pipe / stdin to a hadoop file","command":"cat somefile.tsv | hdfs dfs -put - /file/on/cluster.tsv"},{"id":"25Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs empty trash","command":"hdfs dfs -expunge"},{"id":"26Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs kill yarn job","command":"hadoop job -kill job_id"},{"id":"27Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs rm remove file","command":"hdfs dfs -rm /user/hive/warehouse/blah/blah"},{"id":"28Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs merge all files in a folder to one file","command":"hdfs dfs -getmerge /path/to/folder /path/to/file"},{"id":"29Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs print a compressed file / uncompress a file","command":"hdfs dfs -text /path/to/compressed_file"},{"id":"30Hadoop hdfs#","section":"Hadoop hdfs#","description":"hdfs get rack awareness and number of under replicated blocks","command":"hadoop fsck / -locations -blocks -files | grep -i -C6 miss"},{"id":"31HIVE#","section":"HIVE#","description":"Hive Read / Print sequence files","command":"dfs -text /camus/exec/history/topic/2015-06-16-07-08-14/offsets-m-00000;"},{"id":"32HIVE#","section":"HIVE#","description":"Hive Describe / show partition information (e.g. location of underlying folder in hadoop)","command":"DESCRIBE FORMATTED my_table PARTITION (year=2015,month=03,day=15);"},{"id":"33HIVE#","section":"HIVE#","description":"Hive show table partitions","command":"show partitions my_table;"},{"id":"34HIVE#","section":"HIVE#","description":"Hive Print columns names / headers in CLI","command":"SET hive.cli.print.header=true;"},{"id":"35HIVE#","section":"HIVE#","description":"Hive show name of current database on CLI prompt","command":"SET hive.cli.print.current.db=true;"},{"id":"36HIVE#","section":"HIVE#","description":"Hive create database / schema","command":"CREATE DATABASE test;"},{"id":"37HIVE#","section":"HIVE#","description":"Hive create view","command":"CREATE VIEW view_name(vw_field1, vw_field2)\nAS SELECT field1, field2 FROM base_table;"},{"id":"38HIVE#","section":"HIVE#","description":"Hive lock table","command":"LOCK TABLE my_table;"},{"id":"39HIVE#","section":"HIVE#","description":"Hive lock table partition","command":"LOCK TABLE my_table partition(dt='2015-05-06');"},{"id":"40HIVE#","section":"HIVE#","description":"Hive unlock table / remove table lock","command":"UNLOCK TABLE my_table;"},{"id":"41HIVE#","section":"HIVE#","description":"Hive unlock partition","command":"UNLOCK TABLE my_table partition(dt='2015-05-06');"},{"id":"42HIVE#","section":"HIVE#","description":"Hive rename table","command":"ALTER TABLE table_name RENAME TO new_table_name"},{"id":"43HIVE#","section":"HIVE#","description":"Hive add column to a table","command":"ALTER TABLE my_table ADD new_column string;"},{"id":"44HIVE#","section":"HIVE#","description":"Hive rename column","command":"ALTER TABLE my_table CHANGE old_column new_column string;"},{"id":"45HIVE#","section":"HIVE#","description":"Hive default CLI log file location","command":"/tmp/nameofuser"},{"id":"46HIVE#","section":"HIVE#","description":"Hive select where contain a regex like","command":"SELECT * FROM table WHERE field RLIKE 'REGEX'"},{"id":"47HIVE#","section":"HIVE#","description":"Hive Check version of client running","command":"ps -aux | grep -i \"hive\""},{"id":"48HIVE#","section":"HIVE#","description":"Hive create table example","command":"CREATE TABLE my_table(id int, val string)\nCOMMENT 'my table!'\nPARTITIONED BY (dt string)\nROW FORMAT DELIMITED\n  FIELDS TERMINATED BY \"\\t\"\n  LINES TERMNIATED BY \"\\n\";"},{"id":"49HIVE#","section":"HIVE#","description":"Hive create table as (CTAS)","command":"CREATE TABLE my_table(id int) AS SELECT id from other_table;"},{"id":"50HIVE#","section":"HIVE#","description":"Hive Drop table partition","command":"ALTER TABLE my_table DROP PARTITION (partition_field = 'partition_value',...);"},{"id":"51HIVE#","section":"HIVE#","description":"Hive Drop multiple partitions","command":"ALTER TABLE foo DROP PARTITION(ds < 'date');"},{"id":"52HIVE#","section":"HIVE#","description":"Hive Insert into partition / add partition","command":"INSERT INTO my_table PARTITION (dt='2014-01-01')\nSELECT * from ...;"},{"id":"53HIVE#","section":"HIVE#","description":"Hive add partition to external table","command":"ALTER TABLE my_table ADD PARTITION (dt='2014-01-29') location 'hdfs:///asfd';"},{"id":"54HIVE#","section":"HIVE#","description":"Hive load data (file on local(my computer))","command":"LOAD DATA LOCAL INPATH './my_file.tsv' OVERWRITE INTO TABLE my_table;"},{"id":"55HIVE#","section":"HIVE#","description":"Hive load data (file in HDFS)","command":"LOAD DATA INPATH '/somewhere/on/hadoop.tsv'\nOVERWRITE INTO TABLE my_table PARTITION (ds='2014-01-13');"},{"id":"56HIVE#","section":"HIVE#","description":"Hive prevent accidental dropping of a table","command":"ALTER TABLE my_table ENABLE/DISABLE NO DROP CASCADE;"},{"id":"57HIVE#","section":"HIVE#","description":"Hive Describe function","command":"DESCRIBE FUNCTION EXTENDED function_name;"},{"id":"58HIVE#","section":"HIVE#","description":"Hive Show functions","command":"SHOW FUNCTIONS;"},{"id":"59HIVE#","section":"HIVE#","description":"Hive Add jar on local","command":"ADD JAR /path/to/jar/on/local;"},{"id":"60HIVE#","section":"HIVE#","description":"Hive Add jar on hdfs","command":"ADD JAR hdfs:///path/to/jar/on/hdfs;"},{"id":"61HIVE#","section":"HIVE#","description":"Hive Add functions / UDFs","command":"CREATE TEMPORARY FUNCTION nvl AS 'com.company.hive.udf.GenericUDFNVL';"},{"id":"62HIVE#","section":"HIVE#","description":"Hive data types","command":"Numeric: tinyint, smallint, int, bigint, float, double, decimal\nDate/Time: timestamp, date\nComplex: array, map<key, value>, struct, union"},{"id":"63HIVE#","section":"HIVE#","description":"Add multiple partitions to a HIVE external table (ruby / irb)","command":"(Date.new(2015,2,20)..Date.new(2015,6,12)).each do |x|\n   puts \"alter table your_hive_table add partition (#{x.strftime('year=%Y,month=%m,day=%d')}) location 'hdfs:///hdfs/folder/#{x.strftime('%Y/%m/%d')}';\"\nend"},{"id":"64HIVE#","section":"HIVE#","description":"Hive truncate table","command":"TRUNCATE TABLE my_table;"},{"id":"65HIVE#","section":"HIVE#","description":"Hive recover partitions for \"non-external\" tables","command":"MSCK REPAIR TABLE my_table;"},{"id":"66HIVE#","section":"HIVE#","description":"Hive list of databases","command":"SHOW DATABASES;"},{"id":"67HIVE#","section":"HIVE#","description":"Hive list all tables in current database","command":"SHOW TABLES;"},{"id":"68HIVE#","section":"HIVE#","description":"Hive run query from command line","command":"hive -e \"SELECT * from table;\""},{"id":"69HIVE#","section":"HIVE#","description":"Hive run query from from file","command":"hive -f \"SELECT * from table;\""},{"id":"70HIVE#","section":"HIVE#","description":"Hive CLI run bash command","command":"!cat /tmp/file.txt"},{"id":"71HIVE#","section":"HIVE#","description":"Hive show all variables","command":"SET;"},{"id":"72HIVE#","section":"HIVE#","description":"Hive if syntax","command":"if(boolean testCondition, T valueTrue, T valueFalseOrNull)"},{"id":"73HIVE#","section":"HIVE#","description":"Hive convert ISO-8601 to unix timestamp (requires simplymeasured/hive-udf)","command":"iso8601_to_unix_timestamp('2013-06-10T12:31:00Z')"},{"id":"74HIVE#","section":"HIVE#","description":"Hive convert unix timestamp to a date in specified format","command":"from_unixtime(unix_timestamp_field,'yyyy-MM-dd')"},{"id":"75HIVE#","section":"HIVE#","description":"Hive convert unix timestamp to a date in MySQL format e.g. 1970-01-01 00:00:00","command":"from_unixtime(unix_timestamp_field)"},{"id":"76HIVE#","section":"HIVE#","description":"Hive get current unix timestamp in seconds","command":"unix_timestamp()"},{"id":"77HIVE#","section":"HIVE#","description":"Hive number of days from start to end date / datediff","command":"datediff('2009-03-01', '2009-02-27') = 2"},{"id":"78HIVE#","section":"HIVE#","description":"Hive add days to a date","command":"date_add('2008-12-31', 1)"},{"id":"79HIVE#","section":"HIVE#","description":"Hive subtract days from a date","command":"date_sub('2008-12-31', 1)"},{"id":"80HIVE#","section":"HIVE#","description":"Hive change timezone of a timestamp that is in UTC","command":"from_utc_timestamp('1970-01-01 08:00:00','PST')"},{"id":"81HIVE#","section":"HIVE#","description":"Hive change timezone to UTC of a timestamp that is in a different timezone","command":"to_utc_timestamp('1970-01-01 00:00:00','PST')"},{"id":"82HIVE#","section":"HIVE#","description":"Hive current date / timestamp","command":"current_date / current_timestamp"},{"id":"83HIVE#","section":"HIVE#","description":"Hive check if null","command":"isnull(a)"},{"id":"84HIVE#","section":"HIVE#","description":"Hive case statement","command":"CASE a WHEN b THEN c WHEN d THEN e ELSE f END"},{"id":"85HIVE#","section":"HIVE#","description":"Hive greatest value, compare values","command":"greatest(v1, v2, ...)"},{"id":"86HIVE#","section":"HIVE#","description":"Hive lowest value, compare values","command":"lowest(v1, v2, ...)"},{"id":"87HIVE#","section":"HIVE#","description":"Hive function for concatenate strings","command":"concat(‘foo’, ‘bar’, ...) ;"},{"id":"88HIVE#","section":"HIVE#","description":"Hive function for position of first occurrence in string","command":"instr(string str, string substr)"},{"id":"89HIVE#","section":"HIVE#","description":"Hive function for size / length of a string","command":"length(\"str\") ;"},{"id":"90HIVE#","section":"HIVE#","description":"Hive function to lowercase / uppercase a string","command":"lower(string A) or upper(string A)"},{"id":"91HIVE#","section":"HIVE#","description":"Hive function to capitalize first letter of every word / name capitalization","command":"initcap(\"test str\") -- => Test Str"},{"id":"92HIVE#","section":"HIVE#","description":"Hive function to calculate distance between two strings levenshtein","command":"levenshtein(string A, string B)"},{"id":"93HIVE#","section":"HIVE#","description":"Hive function to trim / strip spaces from string","command":"trim (\"  str  \") or ltrim(\"   str\") or rtrim(\"str   \")"},{"id":"94HIVE#","section":"HIVE#","description":"Hive function to split a string by regex pattern(returns array)","command":"split(string str, string pattern)"},{"id":"95HIVE#","section":"HIVE#","description":"Hive function to substring a field / column","command":"substr(string, int start, int len);"},{"id":"96HIVE#","section":"HIVE#","description":"Hive parse JSON field using Json tuple and lateral view","command":"{\"id\": \"12345\", \"field1\": \"text\", \"field2\": \"text\"}\nSELECT a.field1, a.field2 FROM my_table\nlateral view json_tuple(a.raw, 'field1', 'field2')a as field1, field2;"},{"id":"97HIVE#","section":"HIVE#","description":"Hive parse json string","command":"{\"id\": \"12345\", \"field1\": { \"inner1\": \"text\"}}\nSELECT get_json_object(my_tbl.event_data, '$.field1.inner1') from my_string_table;"},{"id":"98HIVE#","section":"HIVE#","description":"Hive lateral view explode / convert columns to rows","command":"-- here ad_list is an array\nSELECT pageid, adid\nFROM pageAds LATERAL VIEW explode(adid_list) adTable AS adid;"},{"id":"99HIVE#","section":"HIVE#","description":"Hive comment a line (only works in scripts)","command":"-- my comment"}]